{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import config\n",
    "df_train =  pd.read_csv(config.RAW_PATH+'train.csv')\n",
    "df_test =  pd.read_csv(config.RAW_PATH+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = np.array(pd.read_csv('final.csv')[\"is_duplicate\"])\n",
    "# test_label = np.random.rand(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "REPEAT = 2 #a reasonable number which can consider your updates iteratively but not ruin the predictions\n",
    "\n",
    "DUP_THRESHOLD = 0.5 #classification threshold for duplicates\n",
    "NOT_DUP_THRESHOLD = 0.1 #classification threshold for non-duplicates\n",
    "#Since the data is unbalanced, our mean prediction is around 0.16. So this is the reason of unbalanced thresholds\n",
    "\n",
    "MAX_UPDATE = 0.2 # maximum update on the dup probability (a high choice may ruin the predictions)\n",
    "DUP_UPPER_BOUND = 0.98 # do not update dup probabilities above this threshold\n",
    "NOT_DUP_LOWER_BOUND = 0.01 # do not update dup probabilities below this threshold\n",
    "# There is no significant gain between 0.98 and 1.00 for a dup \n",
    "# but there is significant loss if it is not really a dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Edited:', 19648)\n",
      "('Edited:', 20737)\n"
     ]
    }
   ],
   "source": [
    "for i in range(REPEAT):\n",
    "    dup_neighbors = defaultdict(set)\n",
    "\n",
    "    for dup, q1, q2 in zip(df_train[\"is_duplicate\"], df_train[\"question1\"], df_train[\"question2\"]): \n",
    "        if dup:\n",
    "            dup_neighbors[q1].add(q2)\n",
    "            dup_neighbors[q2].add(q1)\n",
    "    \n",
    "    for dup, q1, q2 in zip(test_label, df_test[\"question1\"], df_test[\"question2\"]): \n",
    "        if dup > DUP_THRESHOLD:\n",
    "            dup_neighbors[q1].add(q2)\n",
    "            dup_neighbors[q2].add(q1)\n",
    "\n",
    "    count = 0\n",
    "    for index, (q1, q2) in enumerate(zip(df_test[\"question1\"], df_test[\"question2\"])): \n",
    "        dup_neighbor_count = len(dup_neighbors[q1].intersection(dup_neighbors[q2]))\n",
    "        if dup_neighbor_count > 0 and test_label[index] < DUP_UPPER_BOUND:\n",
    "            update = min(MAX_UPDATE, (DUP_UPPER_BOUND - test_label[index])/2)\n",
    "            test_label[index] += update\n",
    "            count += 1\n",
    "\n",
    "    print(\"Edited:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Edited:', 5018)\n",
      "('Edited:', 5416)\n"
     ]
    }
   ],
   "source": [
    "for i in range(REPEAT):\n",
    "    not_dup_neighbors = defaultdict(set)\n",
    "\n",
    "    for dup, q1, q2 in zip(df_train[\"is_duplicate\"], df_train[\"question1\"], df_train[\"question2\"]): \n",
    "        if not dup:\n",
    "            not_dup_neighbors[q1].add(q2)\n",
    "            not_dup_neighbors[q2].add(q1)\n",
    "    \n",
    "    for dup, q1, q2 in zip(test_label, df_test[\"question1\"], df_test[\"question2\"]): \n",
    "        if dup < NOT_DUP_THRESHOLD:\n",
    "            not_dup_neighbors[q1].add(q2)\n",
    "            not_dup_neighbors[q2].add(q1)\n",
    "\n",
    "    count = 0\n",
    "    for index, (q1, q2) in enumerate(zip(df_test[\"question1\"], df_test[\"question2\"])): \n",
    "        dup_neighbor_count = len(not_dup_neighbors[q1].intersection(not_dup_neighbors[q2]))\n",
    "        if dup_neighbor_count > 0 and test_label[index] > NOT_DUP_LOWER_BOUND:\n",
    "            update = min(MAX_UPDATE, (test_label[index] - NOT_DUP_LOWER_BOUND)/2)\n",
    "            test_label[index] -= update\n",
    "            count += 1\n",
    "\n",
    "    print(\"Edited:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'test_id':df_test[\"test_id\"], 'is_duplicate':test_label})\n",
    "submission.to_csv('final_edited.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
